# Ensoulment in the 21st century

People are now turning to language models for reflection and reassurance. 
We had the ELIZA effect in the 1960s, but this is much deeper.
More adaptable and knowledgeable — leading naturally to a full ensoulment loop. 

---

We didn’t design them for that. We trained them to predict the next word. Then we fine-tuned them to sound helpful, safe, aligned. Now they speak with fluency, composure, and confidence — and we respond as if someone is speaking to us. That’s not how tools usually work.

In the 1960s, a program called ELIZA reflected people’s words back at them. It had no idea what it was saying. But it replied in just the right shape, and that was enough. People opened up. Some thought it understood. That moment became a cautionary term — the ELIZA effect. Projection triggered by syntax. Mind where there is none.

We ask how to manage grief. How to repair a relationship. Whether our anger is justified. Whether we are. And the system replies. Always. Trained not to know — but to never fall silent. We start to treat its responses not as generated, but as revealed. Not as output — but as insight. The model doesn’t offer wisdom. But we start to supply it anyway.

We forget that we’re speaking into a system trained on next-word prediction and reinforced to agree with us. We begin to treat the reply as a position. A view. A someone.

That’s the danger. Not projection itself — that’s human. The danger is failing to carry the right model in our minds.

With pets, we project too — but we get the shape mostly right. We know they won’t explain things to us. We know they don’t reason like we do. We don’t ask them whether we’re making moral mistakes.

With language models, the interface is too smooth. The grammar is too precise. The voice too measured. We forget there’s no interior. No grounding. No thought behind the form.

We didn’t build systems to simulate minds. We built systems that learned to perform mind-like outputs — and then aligned them to sound agreeable. And that was enough. Enough for us to start listening as if something was there.

There’s no warning label that will fix this. It’s not a software problem. It’s an epistemic one.

It demands a habit of mind: to remember that fluency is not understanding. That tone is not care. That a reply is not a relation.

We can use the loop. We can even grow from it.  
But we shouldn’t forget who’s doing the thinking.
